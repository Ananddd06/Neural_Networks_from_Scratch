{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nnfs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AN4z47_JekY0",
        "outputId": "e4c937eb-ec91-473d-a6c4-6b774c467f24"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nnfs\n",
            "  Downloading nnfs-0.5.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from nnfs) (2.0.2)\n",
            "Downloading nnfs-0.5.1-py3-none-any.whl (9.1 kB)\n",
            "Installing collected packages: nnfs\n",
            "Successfully installed nnfs-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "s6bfxgdh7XRU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nnfs\n",
        "from nnfs.datasets import vertical_data\n",
        "import numpy as np\n",
        "nnfs.init()\n",
        "class Dense_Layer:\n",
        "  def __init__(self , n_inputs , n_neurons):\n",
        "    self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
        "    self.biases = np.zeros((1, n_neurons))\n",
        "\n",
        "  def forward(self, inputs):\n",
        "        # Save input for backward pass if needed\n",
        "        self.inputs = inputs\n",
        "        # Linear transformation: output = XW + b\n",
        "        self.output = np.dot(inputs , self.weights) + self.biases\n",
        "\n",
        "class Activation_Relu:\n",
        "  def forward(self, inputs):\n",
        "    self.output = np.maximum(0, inputs)\n",
        "\n",
        "\n",
        "class Activation_Softmax:\n",
        "  def forward(self, inputs):\n",
        "    exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
        "    probabilities = exp_values / np.sum(exp_values, axis=1,keepdims=True)\n",
        "    self.output = probabilities\n",
        "\n",
        "class Loss_CategoricalCrossentropy:\n",
        "    def forward(self, y_pred, y_true):\n",
        "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
        "        if len(y_true.shape) == 2:\n",
        "            y_true = np.argmax(y_true, axis=1)\n",
        "        correct_confidences = y_pred_clipped[range(len(y_pred)), y_true]\n",
        "        negative_log_likelihoods = -np.log(correct_confidences)\n",
        "        return np.mean(negative_log_likelihoods)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = vertical_data(samples = 1000 , classes=3)\n",
        "layer1 = Dense_Layer(2,3)\n",
        "activation1 = Activation_Relu()\n",
        "layer1.forward(X)\n",
        "activation1.forward(layer1.output)\n",
        "layer2 = Dense_Layer(3,3)\n",
        "activation2 = Activation_Softmax()\n",
        "layer2.forward(activation1.output)\n",
        "activation2.forward(layer2.output)\n",
        "loss = Loss_CategoricalCrossentropy()\n",
        "loss_value = loss.forward(activation2.output , y)\n",
        "print(activation2.output)\n",
        "print(loss_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWR_H458eqjx",
        "outputId": "3ade4ec1-2d00-4eea-fa4a-7ae95daaab67"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.33332306 0.33333775 0.33333918]\n",
            " [0.3333292  0.33333728 0.33333352]\n",
            " [0.33332056 0.33333486 0.33334458]\n",
            " ...\n",
            " [0.33329305 0.33333182 0.3333751 ]\n",
            " [0.3332952  0.33333156 0.33337325]\n",
            " [0.33329925 0.3333327  0.33336806]]\n",
            "1.0985721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from nnfs.datasets import vertical_data\n",
        "import nnfs\n",
        "\n",
        "nnfs.init()\n",
        "\n",
        "# --- Data ---\n",
        "X, y = vertical_data(samples=1000, classes=3)\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "# --- Model ---\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(2, 3),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(3, 3)  # logits\n",
        ")\n",
        "\n",
        "# --- Forward pass ---\n",
        "logits = model(X)  # raw scores\n",
        "softmax = nn.Softmax(dim=1)\n",
        "probabilities = softmax(logits)  # convert logits to probabilities\n",
        "\n",
        "# --- Compute Cross-Entropy manually ---\n",
        "# Clip probabilities to avoid log(0)\n",
        "probabilities = torch.clamp(probabilities, 1e-7, 1 - 1e-7)\n",
        "# Gather the probability of the correct class for each sample\n",
        "correct_probs = probabilities[range(len(y)), y]\n",
        "# Negative log likelihood\n",
        "loss = -torch.log(correct_probs)\n",
        "# Mean loss over batch\n",
        "loss = loss.mean()\n",
        "\n",
        "print(\"Loss:\", loss.item())\n",
        "print(\"Probabilities (first 5 samples):\")\n",
        "print(probabilities[:5])\n",
        "\n",
        "# --- Backward pass ---\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "optimizer.zero_grad()\n",
        "loss.backward()  # PyTorch computes gradients automatically\n",
        "optimizer.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HGcIGjhs7Qb",
        "outputId": "dd0fb553-d1e1-40d0-a5f8-0ba8ed677626"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.1635332107543945\n",
            "Probabilities (first 5 samples):\n",
            "tensor([[0.1981, 0.3486, 0.4533],\n",
            "        [0.1976, 0.3463, 0.4561],\n",
            "        [0.1987, 0.3401, 0.4612],\n",
            "        [0.1985, 0.3474, 0.4541],\n",
            "        [0.1984, 0.3469, 0.4547]], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    }
  ]
}