{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nnfs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AN4z47_JekY0",
        "outputId": "e4c937eb-ec91-473d-a6c4-6b774c467f24"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nnfs\n",
            "  Downloading nnfs-0.5.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from nnfs) (2.0.2)\n",
            "Downloading nnfs-0.5.1-py3-none-any.whl (9.1 kB)\n",
            "Installing collected packages: nnfs\n",
            "Successfully installed nnfs-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "s6bfxgdh7XRU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nnfs\n",
        "from nnfs.datasets import vertical_data\n",
        "import numpy as np\n",
        "nnfs.init()\n",
        "class Dense_Layer:\n",
        "  def __init__(self , n_inputs , n_neurons):\n",
        "    self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
        "    self.biases = np.zeros((1, n_neurons))\n",
        "\n",
        "  def forward(self, inputs):\n",
        "        # Save input for backward pass if needed\n",
        "        self.inputs = inputs\n",
        "        # Linear transformation: output = XW + b\n",
        "        self.output = np.dot(inputs , self.weights) + self.biases\n",
        "\n",
        "class Activation_Relu:\n",
        "  def forward(self, inputs):\n",
        "    self.output = np.maximum(0, inputs)\n",
        "\n",
        "\n",
        "class Activation_Softmax:\n",
        "  def forward(self, inputs):\n",
        "    exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
        "    probabilities = exp_values / np.sum(exp_values, axis=1,keepdims=True)\n",
        "    self.output = probabilities\n",
        "\n",
        "class Loss_CategoricalCrossentropy:\n",
        "    def forward(self, y_pred, y_true):\n",
        "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
        "        if len(y_true.shape) == 2:\n",
        "            y_true = np.argmax(y_true, axis=1)\n",
        "        correct_confidences = y_pred_clipped[range(len(y_pred)), y_true]\n",
        "        negative_log_likelihoods = -np.log(correct_confidences)\n",
        "        return np.mean(negative_log_likelihoods)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = vertical_data(samples = 1000 , classes=3)\n",
        "layer1 = Dense_Layer(2,3)\n",
        "activation1 = Activation_Relu()\n",
        "layer1.forward(X)\n",
        "activation1.forward(layer1.output)\n",
        "layer2 = Dense_Layer(3,3)\n",
        "activation2 = Activation_Softmax()\n",
        "layer2.forward(activation1.output)\n",
        "activation2.forward(layer2.output)\n",
        "loss = Loss_CategoricalCrossentropy()\n",
        "loss_value = loss.forward(activation2.output , y)\n",
        "print(activation2.output)\n",
        "print(loss_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWR_H458eqjx",
        "outputId": "3ade4ec1-2d00-4eea-fa4a-7ae95daaab67"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.33332306 0.33333775 0.33333918]\n",
            " [0.3333292  0.33333728 0.33333352]\n",
            " [0.33332056 0.33333486 0.33334458]\n",
            " ...\n",
            " [0.33329305 0.33333182 0.3333751 ]\n",
            " [0.3332952  0.33333156 0.33337325]\n",
            " [0.33329925 0.3333327  0.33336806]]\n",
            "1.0985721\n"
          ]
        }
      ]
    }
  ]
}